# WOFO - RAG-Based Enterprise Knowledge Offline Assistant 

<img width="1919" height="1079" alt="Screenshot 2025-12-30 214946" src="https://github.com/user-attachments/assets/2c529fc6-95a8-4ebc-996a-43e144438103" />
<img width="1919" height="1079" alt="Screenshot 2025-12-30 214939" src="https://github.com/user-attachments/assets/525673d8-52ef-4b92-a195-8ca7d6232253" />
<img width="1919" height="1079" alt="Screenshot 2025-12-30 215007" src="https://github.com/user-attachments/assets/149f3481-db26-4d9b-8acf-6ae97133f91a" />
<img width="1919" height="1079" alt="Screenshot 2025-12-30 215032" src="https://github.com/user-attachments/assets/6b9c9b9b-2738-4c53-b4ed-2c788765c584" />
<img width="1919" height="1079" alt="Screenshot 2025-12-30 215041" src="https://github.com/user-attachments/assets/f62ae156-751a-4046-b089-94ab46100809" />
<img width="1917" height="1079" alt="image" src="https://github.com/user-attachments/assets/db3e4f92-e543-4130-89de-11ee8d5c8011" />
<img width="1919" height="965" alt="image" src="https://github.com/user-attachments/assets/e88db51d-b427-4f06-bb46-d7b47e38bf49" />



A **Retrieval-Augmented Generation (RAG)** system designed for organizations to securely upload internal documents (policies, manuals, legal docs, FAQs, etc.) and allow employees to query them using natural language.

This system converts private documents into searchable vector embeddings and uses a Large Language Model (LLM) to generate accurate, context-aware answers â€” **strictly based on company data**.

---

## Key Features

*  Upload PDFs, DOCX, TXT files
*  Automatic text extraction & chunking
*  Semantic search using vector embeddings
*  LLM-powered question answering
*  Company-wise isolated data access
*  Role-based access (Admin/Employee)
*  Chat and memory stores in database
*  Fast similarity search using Qdrant
*  Modular & scalable architecture

---

## System Architecture (High-Level)

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Admin Uploads Docs   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                  Text Extraction & Chunking
                           â”‚
                  Embedding Generation (HF)
                           â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   Vector Database     â”‚  â† Qdrant
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
       User Query â†’ Embed â†’ Similarity Search
                           â”‚
                    Relevant Context
                           â”‚
                   LLM (Gemini / LLaMA)
                           â”‚
                     Final Answer
```

---

##  Tech Stack

### Backend

* **Node.js**
* **Express.js**

### Frontend

* **React**

### AI / ML

* **Embedding Model:** HuggingFace Sentence Transformer
* **LLM:** Gemini 3 Flash (can be replaced with LLaMA)
* **Vector DB:** Qdrant

### Database

* **MongoDB** â€“ Users, Chats, Metadata

### Tools

* **Docker** â€“ Running Qdrant
* **Postman** â€“ API Testing

---

## ğŸ”„ RAG FLOW EXPLAINED

### 1ï¸âƒ£ Ingestion Pipeline

Used when **admin uploads documents**.

1. Extract text from PDF/DOCX 
2. Clean & normalize text 
3. Split into semantic chunks 
4. Convert chunks into embeddings for embedding we are using HuggingFace Sentence Transformer model 
5. Store embeddings in **Qdrant** (Qdrant is our VectorDB that stores the embededChunks and its metadata)

---

### 2ï¸âƒ£ Query Pipeline (User Chat)

1. User enters a question
2. Question is converted to vector using same embedding model 
3. Vector similarity search in Qdrant
4. Top-N relevant chunks retrieved
5. It filter the chunks and create context for LLM 
6. Context + question passed to LLM ( currently we use gemini-3-flash-preview )
7. LLM generates accurate answer

---

## ğŸ§  Example Flow

```
User: "What is the company leave policy?"

â†’ Embed question 
â†’ Search vector DB
â†’ Retrieve related policy chunks
â†’ Send to LLM
â†’ Return summarized answer
```

---

## ğŸ”§ Installation & Setup

### 1ï¸âƒ£ Clone Repository

```bash
git clone <repo-url>
cd project
```

### 2ï¸âƒ£ Install Dependencies

```bash
npm install
```

### 3ï¸âƒ£ Setup Environment Variables

Create `.env` file:

```env
PORT=3000
MONGO_URI=your_mongodb_url
JWT_SECRET=your_secret
GEMINI_API_KEY=your_gemini_key
```

---

### 4ï¸âƒ£ Run Vector Database (Qdrant)

```bash
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant
```

---

### 5ï¸âƒ£ Start Backend Server

```bash
node server.js
```

---

## ğŸ§ª API Endpoints

### â¤ Upload Documents

```
POST /api/upload/ingestion
```

### â¤ Ask Question

```
POST /api/search/retrieval
{
  "question": "What is the leave policy?"
}
```
This two are main RAG API points 

Other API Endpoints - 

âœ… Authentication (2/2)
POST /api/auth/login - User login
POST /api/auth/register - User registration
âœ… File Management (4/4)
GET /api/files/ - List files (Admin)
GET /api/files/:id - File details
DELETE /api/files/:id - Delete file (Admin)
GET /api/files/stats/overview - File statistics
âœ… Search & RAG (2/2)
POST /api/chatbot/query - Conversational AI assistant
GET /api/chatbot/status - Chatbot health
âœ… User Management (3/3)
GET /api/users - List users (Admin)
GET /api/users/test - Test endpoint
GET /api/analytics/user/:id - User analytics
âœ… Analytics (3/3)
GET /api/analytics/system - System stats (Admin)
GET /api/analytics/queries/recent - Query history
GET /api/analytics/dashboard - Dashboard data
âœ… File Monitoring (2/2)
POST /api/monitor/scan - Manual scan (Admin)
GET /api/monitor/status - Monitoring status
âœ… Employee (1/1)
POST /api/auth/employee-register - Employee registration

---

## Technologies Used

| Component      | Technology       |
| -------------- | ---------------- |
| Backend        | Node.js, Express |
| Vector DB      | Qdrant           |
| Embeddings     | HuggingFace      |
| LLM            | Gemini 3 Flash   |
| Database       | MongoDB          |
| Authentication | JWT              |
| Deployment     | Docker           |

---

## Team Members

| Name                  | Role                      |
| --------------------- | ------------------------- |
| **Varun Kushwaha**    | Backend Developer         |
| **Ahad Dangarwavala** | Backend Developer         |
| **Dhruv Gohel**       | Frontend Developer        |
| **Nikunj Makwana**    | Frontend Developer        |
| **Vishmayraj Zala**   | Authentication & Database |

---

## Future Enhancements

* Multi-company isolation
* Streaming responses
* Model switching (Gemini â†” LLaMA)
* UI dashboard for admins

---

## Final Notes

This system is designed to be:

* Secure
*  Fast
*  Intelligent
*  Scalable

It enables organizations to **safely query their private data using AI** â€” without leaking information externally.

---
