/**
 * Populate Vector Database with Existing Documents
 * -----------------------------------------------
 * This script processes existing files and stores their embeddings in Qdrant
 */

const mongoose = require('mongoose');
const dotenv = require('dotenv');
const fs = require('fs');
const path = require('path');

dotenv.config();

// Import services
const { extractText } = require('./services/textExtractor');
const { chunkText } = require('./services/chunkGenerator');
const { generateEmbeddings } = require('./services/embeddingService');
const { initVectorDB, insertVectors } = require('./services/vectorDB');

// Import models
const StoredFiles = require('./models/storedFiles');

async function populateVectorDB() {
  try {
    console.log('üöÄ Starting Vector DB Population...');
    
    // Connect to MongoDB
    await mongoose.connect(process.env.MONGO_URL);
    console.log('‚úÖ Connected to MongoDB');
    
    // Initialize Vector DB
    await initVectorDB();
    console.log('‚úÖ Vector DB initialized');
    
    // Get all completed files
    const files = await StoredFiles.find({ ingestionStatus: 'COMPLETED' });
    console.log(`üìÅ Found ${files.length} files to process`);
    
    let totalChunks = 0;
    
    for (const file of files) {
      try {
        console.log(`\nüìÑ Processing: ${file.originalFilename}`);
        
        // Check if file exists
        if (!fs.existsSync(file.filePath)) {
          console.log(`‚ö†Ô∏è File not found: ${file.filePath}`);
          continue;
        }
        
        // Extract text
        console.log('üîç Extracting text...');
        const text = await extractText(file.filePath);
        
        if (!text || text.length < 50) {
          console.log('‚ö†Ô∏è Text too short, skipping');
          continue;
        }
        
        console.log(`üìÑ Extracted ${text.length} characters`);
        
        // Chunk text
        console.log('‚úÇÔ∏è Chunking text...');
        const chunks = chunkText(text, { 
          source: file.originalFilename,
          document_id: file.documentId 
        });
        
        console.log(`üì¶ Created ${chunks.length} chunks`);
        
        // Generate embeddings
        console.log('üß† Generating embeddings...');
        const embeddedChunks = await generateEmbeddings(chunks);
        
        console.log(`üéØ Generated ${embeddedChunks.length} embeddings`);
        
        // Insert into vector DB
        console.log('üíæ Storing in vector DB...');
        await insertVectors(embeddedChunks);
        
        totalChunks += embeddedChunks.length;
        console.log(`‚úÖ Successfully processed ${file.originalFilename}`);
        
      } catch (error) {
        console.error(`‚ùå Error processing ${file.originalFilename}:`, error.message);
      }
    }
    
    console.log(`\nüéâ Vector DB Population Complete!`);
    console.log(`üìä Total chunks processed: ${totalChunks}`);
    console.log(`üìö Documents added to vector search`);
    
  } catch (error) {
    console.error('‚ùå Population error:', error);
  } finally {
    await mongoose.disconnect();
    console.log('üîå Disconnected from MongoDB');
  }
}

// Run the population
populateVectorDB();
